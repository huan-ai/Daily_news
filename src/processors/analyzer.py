"""
æ–°é—»åˆ†ææ¨¡å—

ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æï¼Œå½“LLMä¸å¯ç”¨æ—¶è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„ä¸­æ–‡æ—¥æŠ¥
"""

import asyncio
import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from collections import defaultdict

from ..collectors.base import NewsItem, NewsCategory
from ..utils.logger import log
from ..utils.llm_client import GeminiClient


class NewsAnalyzer:
    """
    æ–°é—»åˆ†æå™¨
    
    ä½¿ç”¨Geminiå¯¹æ”¶é›†çš„æ–°é—»è¿›è¡Œæ·±åº¦åˆ†æ
    """
    
    def __init__(self, llm_client: Optional[GeminiClient] = None):
        self.llm = llm_client or GeminiClient()
    
    async def summarize_item(self, item: NewsItem) -> str:
        try:
            summary = await self.llm.summarize(item.content)
            item.summary = summary
            return summary
        except Exception as e:
            log.error(f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
            return item.content[:200]
    
    async def analyze_news(self, items: List[NewsItem]) -> str:
        if not items:
            return "ä»Šæ—¥æš‚æ— é‡è¦AIè¡Œä¸šåŠ¨æ€ã€‚"
        
        news_text = self._format_news_for_analysis(items)
        
        try:
            analysis = await self.llm.analyze(news_text)
            return analysis
        except Exception as e:
            log.error(f"æ·±åº¦åˆ†æå¤±è´¥: {e}")
            return self._fallback_analysis(items)
    
    def _format_news_for_analysis(self, items: List[NewsItem]) -> str:
        grouped: Dict[str, List[NewsItem]] = defaultdict(list)
        for item in items:
            grouped[item.category.value].append(item)
        
        lines = []
        for category, category_items in grouped.items():
            lines.append(f"\n## {category}")
            for i, item in enumerate(category_items[:5], 1):
                lines.append(f"\n### {i}. {item.title}")
                lines.append(f"æ¥æº: {item.source}")
                if item.url:
                    lines.append(f"é“¾æ¥: {item.url}")
                content_text = item.content[:1000] if item.content else ""
                lines.append(f"\n{content_text}")
                if item.extra:
                    if item.extra.get("description"):
                        lines.append(f"\né¡¹ç›®æè¿°: {item.extra['description']}")
                    if item.extra.get("stars"):
                        lines.append(f"Staræ•°: {item.extra['stars']}")
        return "\n".join(lines)
    
    # ===== æ™ºèƒ½ä¸­æ–‡å†…å®¹ç”Ÿæˆï¼ˆæ— éœ€ LLMï¼‰ =====
    
    def _extract_clean_readme(self, readme: str, max_len: int = 400) -> str:
        """ä» README ä¸­æå–å¹²å‡€çš„æ–‡å­—æè¿°"""
        if not readme:
            return ""
        
        # å»æ‰ HTML æ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', readme)
        # å»æ‰ markdown å›¾ç‰‡
        text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
        # å»æ‰ markdown é“¾æ¥ä½†ä¿ç•™æ–‡å­—
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
        # å»æ‰æ ‡é¢˜ç¬¦å·
        text = re.sub(r'^#{1,6}\s*', '', text, flags=re.MULTILINE)
        # å»æ‰ badge/shield
        text = re.sub(r'\[!\[.*?\]\(.*?\)\]\(.*?\)', '', text)
        # å»æ‰å¤šä½™ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)
        # å»æ‰é¦–å°¾ç©ºç™½
        text = text.strip()
        
        # å–å‰ N ä¸ªå­—ç¬¦ï¼Œåœ¨å¥æœ«æˆªæ–­
        if len(text) > max_len:
            cutoff = text[:max_len].rfind('.')
            if cutoff > max_len * 0.5:
                text = text[:cutoff + 1]
            else:
                cutoff = text[:max_len].rfind('\n')
                if cutoff > max_len * 0.5:
                    text = text[:cutoff]
                else:
                    text = text[:max_len] + "..."
        
        return text
    
    def _generate_project_intro(self, item: NewsItem) -> str:
        """
        ä¸º GitHub é¡¹ç›®ç”Ÿæˆ githubdaily é£æ ¼çš„ä¸­æ–‡ä»‹ç»
        
        æ ¼å¼å‚è€ƒï¼š
        - ä¸€å¥è¯æ¦‚æ‹¬
        - æ ¸å¿ƒäº®ç‚¹
        - æ¨èç†ç”±
        """
        extra = item.extra or {}
        repo_path = extra.get("repo_path", "")
        description = extra.get("description", "")
        stars = extra.get("stars", "N/A")
        today_stars = extra.get("today_stars", "")
        language = extra.get("language", "")
        readme = extra.get("readme_snippet", "")
        url = item.url or f"https://github.com/{repo_path}"
        
        # æ¸…ç† README æ–‡æœ¬
        readme_text = self._extract_clean_readme(readme, 300)
        
        lines = []
        
        # é¡¹ç›®å + çƒ­åº¦
        lines.append(f"### ğŸ“Œ [{repo_path}]({url})")
        lines.append("")
        
        # Stars ä¿¡æ¯è¡Œ
        star_info = f"â­ **{stars}** Stars"
        if today_stars:
            # æ¸…ç† today_stars æ–‡æœ¬
            ts = today_stars.replace("stars today", "").replace("star today", "").strip()
            star_info += f"  |  ğŸ“ˆ ä»Šæ—¥æ–°å¢ **{ts}**"
        if language and language != "Unknown":
            star_info += f"  |  ğŸ’» {language}"
        lines.append(star_info)
        lines.append("")
        
        # ä¸€å¥è¯ç®€ä»‹
        if description:
            lines.append(f"**ç®€ä»‹**ï¼š{description}")
            lines.append("")
        
        # é¡¹ç›®è¯¦æƒ…ï¼ˆæ¥è‡ª READMEï¼‰
        if readme_text:
            lines.append(f"**é¡¹ç›®è¯¦æƒ…**ï¼š{readme_text}")
            lines.append("")
        
        # æ¨èç†ç”± â€” æ ¹æ® star å¢é•¿å’Œæè¿°è‡ªåŠ¨ç”Ÿæˆ
        if today_stars:
            ts_clean = re.sub(r'[^\d,]', '', today_stars.replace(",", ""))
            try:
                ts_num = int(ts_clean) if ts_clean else 0
            except ValueError:
                ts_num = 0
            
            if ts_num > 500:
                lines.append(f"ğŸ”¥ **æ¨èç†ç”±**ï¼šä»Šæ—¥ Star å¢é•¿è¿…çŒ›ï¼ˆ+{ts_num}ï¼‰ï¼Œç¤¾åŒºå…³æ³¨åº¦æé«˜ï¼Œå€¼å¾—é‡ç‚¹å…³æ³¨ã€‚")
            elif ts_num > 100:
                lines.append(f"ğŸ‘ **æ¨èç†ç”±**ï¼šä»Šæ—¥æ–°å¢ {ts_num} Starsï¼Œå±äºæŒç»­çƒ­é—¨é¡¹ç›®ã€‚")
        
        lines.append("")
        return "\n".join(lines)
    
    def _generate_news_item_cn(self, item: NewsItem, index: int) -> str:
        """
        å°†è‹±æ–‡æ–°é—»æ¡ç›®è½¬æ¢ä¸ºä¸­æ–‡æ ¼å¼çš„ç®€æŠ¥
        """
        title = item.title or ""
        content = item.content or ""
        url = item.url or ""
        source = item.source or ""
        
        # æ¸…ç† HN æ ¼å¼çš„å†…å®¹
        clean_content = content
        clean_content = re.sub(r'Article URL:\s*\n\s*https?://\S+', '', clean_content)
        clean_content = re.sub(r'Comments URL:\s*\n\s*https?://\S+', '', clean_content)
        clean_content = re.sub(r'Points:\s*\d+', '', clean_content)
        clean_content = re.sub(r'#\s*Comments:\s*\d+', '', clean_content)
        clean_content = clean_content.strip()
        
        # æå–æœ‰ç”¨çš„å†…å®¹æ‘˜è¦
        if clean_content and len(clean_content) > 20:
            brief = clean_content[:200].strip()
            if len(clean_content) > 200:
                brief += "..."
        else:
            brief = ""
        
        lines = []
        lines.append(f"**{index}. {title}**")
        if source:
            lines.append(f"*æ¥æºï¼š{source}*")
        lines.append("")
        
        if brief:
            lines.append(f"> {brief}")
            lines.append("")
        
        if url:
            lines.append(f"ğŸ”— [æŸ¥çœ‹è¯¦æƒ…]({url})")
        lines.append("")
        
        return "\n".join(lines)
    
    def _fallback_analysis(self, items: List[NewsItem]) -> str:
        """
        é™çº§åˆ†æ â€” æŒ‰ githubdaily / æœºå™¨ä¹‹å¿ƒé£æ ¼ç”Ÿæˆä¸­æ–‡å†…å®¹
        """
        categories = {}
        for item in items:
            cat = item.category.value
            categories[cat] = categories.get(cat, 0) + 1
        
        # GitHub é¡¹ç›®
        github_items = [item for item in items if item.source == "GitHub Trending"]
        non_github_items = [item for item in items if item.source != "GitHub Trending"]
        
        lines = []
        
        # ===== GitHub çƒ­é—¨é¡¹ç›®ç²¾é€‰ =====
        if github_items:
            lines.append("## ğŸ”¥ GitHub çƒ­é—¨é¡¹ç›®ç²¾é€‰")
            lines.append("")
            lines.append(f"ä»Šæ—¥å…±æœ‰ **{len(github_items)}** ä¸ªAIç›¸å…³é¡¹ç›®ç™»ä¸Š GitHub Trendingï¼Œä»¥ä¸‹æ˜¯æœ€å€¼å¾—å…³æ³¨çš„é¡¹ç›®ï¼š")
            lines.append("")
            
            for item in github_items[:5]:
                lines.append(self._generate_project_intro(item))
        
        # ===== è¡Œä¸šåŠ¨æ€ =====
        if non_github_items:
            lines.append("## ğŸ“° è¡Œä¸šåŠ¨æ€")
            lines.append("")
            
            for i, item in enumerate(non_github_items[:8], 1):
                lines.append(self._generate_news_item_cn(item, i))
        
        return "\n".join(lines)
    
    async def generate_report(
        self,
        items: List[NewsItem],
        analysis: str,
        date: Optional[datetime] = None
    ) -> str:
        date = date or datetime.now()
        date_str = date.strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        news_summary = self._prepare_summary(items)
        
        try:
            report = await self.llm.generate_report(
                date=date_str,
                news_summary=news_summary,
                analysis=analysis
            )
            return report
        except Exception as e:
            log.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return self._generate_fallback_report(items, analysis, date_str)
    
    def _prepare_summary(self, items: List[NewsItem]) -> str:
        lines = []
        sorted_items = sorted(items, key=lambda x: (
            0 if x.importance == "é«˜" else (1 if x.importance == "ä¸­" else 2),
            x.category.value
        ))
        
        for item in sorted_items[:15]:
            lines.append(f"\n### ã€{item.category.value}ã€‘{item.title}")
            lines.append(f"æ¥æºï¼š{item.source}")
            if item.url:
                lines.append(f"é“¾æ¥ï¼š{item.url}")
            if item.content:
                lines.append(f"\n{item.content[:600]}")
            if item.summary:
                lines.append(f"\næ‘˜è¦ï¼š{item.summary[:150]}")
        
        return "\n".join(lines)
    
    def _generate_fallback_report(
        self,
        items: List[NewsItem],
        analysis: str,
        date_str: str
    ) -> str:
        """
        ç”Ÿæˆé«˜è´¨é‡é™çº§æŠ¥å‘Š â€” githubdaily / æœºå™¨ä¹‹å¿ƒé£æ ¼
        """
        github_items = [item for item in items if item.source == "GitHub Trending"]
        non_github_items = [item for item in items if item.source != "GitHub Trending"]
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        categories = {}
        for item in items:
            cat = item.category.value
            categories[cat] = categories.get(cat, 0) + 1
        
        lines = [
            f"# ğŸ¤– AIæ—¥æŠ¥ | {date_str}",
            "",
            f"> æ¯æ—¥ç²¾é€‰ AI é¢†åŸŸæœ€å€¼å¾—å…³æ³¨çš„å¼€æºé¡¹ç›®ä¸è¡Œä¸šåŠ¨æ€",
            "",
        ]
        
        # ===== ä»Šæ—¥é€Ÿè§ˆ =====
        lines.append("## âœ¨ ä»Šæ—¥é€Ÿè§ˆ")
        lines.append("")
        
        total = sum(categories.values())
        lines.append(f"ä»Šæ—¥å…±æ”¶å½• **{total}** æ¡AIç›¸å…³åŠ¨æ€ï¼š")
        
        cat_parts = []
        for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
            cat_parts.append(f"{cat}ï¼ˆ{count}æ¡ï¼‰")
        lines.append("ã€".join(cat_parts) + "ã€‚")
        lines.append("")
        
        # ç”¨å‰ 3 ä¸ª GitHub é¡¹ç›®åšäº®ç‚¹
        if github_items:
            for i, item in enumerate(github_items[:3], 1):
                extra = item.extra or {}
                desc = extra.get("description", "")
                repo_path = extra.get("repo_path", item.title)
                ts = extra.get("today_stars", "")
                ts_clean = re.sub(r'[^\d,]', '', ts) if ts else ""
                
                if desc:
                    lines.append(f"- ğŸ”¥ **{repo_path}**ï¼š{desc}ï¼ˆä»Šæ—¥ +{ts_clean} â­ï¼‰")
                else:
                    lines.append(f"- ğŸ”¥ **{repo_path}**ï¼ˆä»Šæ—¥ +{ts_clean} â­ï¼‰")
        
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # ===== åˆ†æå†…å®¹ =====
        if analysis:
            lines.append(analysis)
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # ===== ğŸ“ èµ„æºé“¾æ¥ =====
        lines.append("## ğŸ“ ä»Šæ—¥èµ„æºæ±‡æ€»")
        lines.append("")
        
        if github_items:
            lines.append("**å¼€æºé¡¹ç›®**ï¼š")
            for item in github_items[:6]:
                extra = item.extra or {}
                repo_path = extra.get("repo_path", "")
                stars = extra.get("stars", "")
                if item.url:
                    lines.append(f"- [{repo_path}]({item.url})ï¼ˆâ­ {stars}ï¼‰")
            lines.append("")
        
        if non_github_items:
            lines.append("**å»¶ä¼¸é˜…è¯»**ï¼š")
            for item in non_github_items[:5]:
                if item.url:
                    title = item.title.replace("Show HN: ", "").replace("Ask HN: ", "")
                    lines.append(f"- [{title}]({item.url})")
            lines.append("")
        
        lines.extend([
            "---",
            "",
            f"*æœ¬æ—¥æŠ¥ç”± AI è‡ªåŠ¨æ•´ç†ç”Ÿæˆäº{date_str}ï¼Œè¿½è¸ªAIå‰æ²¿åŠ¨æ€ã€‚*",
            f"*å…³æ³¨æˆ‘ä»¬ï¼Œæ¯æ—¥ 20:00 å‡†æ—¶æ¨é€ï¼*"
        ])
        
        return "\n".join(lines)
